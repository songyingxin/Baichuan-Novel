## 项目简介
NovelGPT（文创）是一个开源的中文大语言模型，本项目的目的是基于现有的开源大模型如 Baichuan2，Lamma 2 来接着预训练网文。
此外，考虑到实际使用中，网文的使用场景更丰富，因此本项目会不断扩充场景。
当前，本项目致力于AI网文续写，帮助作者提高写作效率。

## 项目内容
本项目依托于网文数据，主要进行以下几个方面的工作：
- 基于网文数据进行预训练，全参数微调，LoRA微调，QLoRA 等
- 支持主流的开源大模型，如 baichuan2，lamma 2等
- 支持 lora 与 base model 权重合并
- 模型优化：针对小说场景下的生成问题进行模型结构优化，致力于解决小说超长文本问题。
- 开源部分小说数据集

## 环境
4* A100 40G

## 模型下载
待定

## 项目代码介绍

## 数据

## 模型预训练


## 模型微调

### 全参数微调

## LoRA 微调

## QLoRA 微调


## 推理加速
